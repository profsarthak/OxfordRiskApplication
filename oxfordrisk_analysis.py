# -*- coding: utf-8 -*-
"""OxfordRisk_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h-dpeZtBgLMLrcQEMryR5TZvlNS-VywO
"""

## Loading the necessary libraries
# Data handling
import pandas as pd
import numpy as np

# HTTP requests
import requests
import json

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Display settings
pd.set_option('display.max_columns', None)
sns.set(style="whitegrid")

"""# **Part 1: Finding the Individual with the Highest Asset Value (GBP)**

*Loading The Necessary Datasets*
"""

# Personality dataset from GitHub
personality_url = "https://raw.githubusercontent.com/karwester/behavioural-finance-task/refs/heads/main/personality.csv"

# Converting it into a dataframe
personality_df = pd.read_csv(personality_url)

# Glimpsing the data
print("Shape of Personality Data:", personality_df.shape)
personality_df.head()

# Check data structure of personality data
print("📋 Personality Dataset Overview:")
personality_df.info()
display(personality_df.describe(include='all'))

# Supabase credentials
SUPABASE_URL = "https://pvgaaikztozwlfhyrqlo.supabase.co"
API_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InB2Z2FhaWt6dG96d2xmaHlycWxvIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDc4NDE2MjUsImV4cCI6MjA2MzQxNzYyNX0.iAqMXnJ_sJuBMtA6FPNCRcYnKw95YkJvY3OhCIZ77vI"

# API endpoint
url = f"{SUPABASE_URL}/rest/v1/assets?select=*"

# Headers with API key
headers = {
    "apikey": API_KEY,
    "Authorization": f"Bearer {API_KEY}"
}

# Requesting the data
response = requests.get(url, headers=headers)

# Checking for success
if response.status_code == 200:
    assets_data = response.json()
    assets_df = pd.DataFrame(assets_data)
    print("Shape of Assets Data:", assets_df.shape)
    display(assets_df.head())
else:
    print("Failed to fetch data:", response.status_code)

# Check data structure of assets data
print("\n📋 Assets Dataset Overview:")
assets_df.info()
display(assets_df.describe(include='all'))

"""*Merging Dataframes for Analysis*

"""

# Merging assets and personality data on identifier `_id`
merged_df = assets_df.merge(personality_df, on="_id", how="left")

print("Merged dataframe shape:", merged_df.shape)
merged_df.head()

# Counting number of assets per person
merged_df['_id'].value_counts().head()

"""*Finding the individual with the highest asset value in GBP and their risk tolerance score*"""

# Step 1: Filtering for GBP assets only
gbp_assets = merged_df[merged_df['asset_currency'] == 'GBP'].copy()

# Step 2: Grouping by _id and adding the GBP asset values
gbp_totals = gbp_assets.groupby('_id')['asset_value'].sum().reset_index()
gbp_totals.rename(columns={'asset_value': 'total_gbp_assets'}, inplace=True)

# Step 3: Bringing risk tolerance back in (but dropping duplicates to get one row per person)
risk_tolerance_map = merged_df[['_id', 'risk_tolerance']].drop_duplicates()

# Step 4: Merging to get risk tolerance alongside total assets
gbp_summary = gbp_totals.merge(risk_tolerance_map, on='_id', how='left')

# Step 5: Sorting in descending order to find the top person
gbp_summary.sort_values(by='total_gbp_assets', ascending=False, inplace=True)

# Displaying the top result
top_person = gbp_summary.iloc[0]
print("Highest asset value (in GBP) individual risk tolerance:", round(top_person['risk_tolerance'], 2))
top_person

"""# **Part 2: Exploratory Data Analysis**

*Question 1: What kinds of investors are we dealing with?*
"""

# Full risk tolerance dataset
risk_scores = personality_df['risk_tolerance']

# Summary stats
print("Risk Tolerance Summary:")
display(risk_scores.describe())

# Defining outlier thresholds
q1 = risk_scores.quantile(0.25)
q3 = risk_scores.quantile(0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr

# Identifing behavioral outliers
behavioral_outliers = personality_df[
    (risk_scores < lower_bound) | (risk_scores > upper_bound)
]

print(f"Number of Behavioral Outliers (Risk Tolerance): {len(behavioral_outliers)}")

# Distribution plot
plt.figure(figsize=(10, 5))
sns.histplot(risk_scores, bins=20, kde=True, color='steelblue')
plt.axvline(lower_bound, color='red', linestyle='--', label='Lower Outlier Threshold')
plt.axvline(upper_bound, color='red', linestyle='--', label='Upper Outlier Threshold')
plt.title("Distribution of Risk Tolerance (Full Sample)")
plt.xlabel("Risk Tolerance Score")
plt.ylabel("Frequency")
plt.legend()
plt.grid(True)
plt.show()

# Correlation with and without outliers
risk_scores_no_outliers = personality_df[
    (personality_df['risk_tolerance'] >= lower_bound) &
    (personality_df['risk_tolerance'] <= upper_bound)
]['risk_tolerance']

print("Mean risk tolerance with outliers:", risk_scores.mean())
print("Mean risk tolerance without outliers:", risk_scores_no_outliers.mean())

# Outlier treatment note
# Decision: Outliers in risk_tolerance were retained in all subsequent analyses.
# Rationale:
# - Only 5 out of 297 individuals were flagged (≈1.7%)
# - Visual inspection showed they fall within a plausible behavioral range
# - Removing them had negligible effect on correlation coefficients (verified)

"""*Question 2: What do they hold — and how much?*"""

# Using existing gbp_assets DataFrame

# Summary statistics
print("GBP Asset Value Summary:")
display(gbp_assets['asset_value'].describe())

# Plotting distribution (log y-axis for better visibility)
plt.figure(figsize=(10, 5))
sns.histplot(gbp_assets['asset_value'], bins=30, color='darkgreen')
plt.title("Distribution of GBP Asset Values")
plt.xlabel("GBP Asset Value (£)")
plt.ylabel("Frequency")
plt.grid(True)
plt.show()

# Total GBP assets per person
gbp_totals = gbp_assets.groupby('_id')['asset_value'].sum().reset_index()
gbp_totals.rename(columns={'asset_value': 'total_gbp_assets'}, inplace=True)

# Flagging top 5% asset holders
top_5_threshold = gbp_totals['total_gbp_assets'].quantile(0.95)
top_gbp_holders = gbp_totals[gbp_totals['total_gbp_assets'] >= top_5_threshold]

print(f"Top 5% GBP Asset Threshold: £{round(top_5_threshold, 2)}")
print(f"Number of Financial Outliers (Top 5%): {len(top_gbp_holders)}")
display(top_gbp_holders.head())

"""*Question 3: Do their behaviors match their beliefs?*"""

# Merging total GBP assets with personality traits
gbp_behavior_df = gbp_totals.merge(personality_df, on='_id', how='left')

# Defining behavioral thresholds
risk_high = 0.6
risk_low = 0.4
asset_median = gbp_behavior_df['total_gbp_assets'].median()
asset_top_25 = gbp_behavior_df['total_gbp_assets'].quantile(0.75)

# Case 1: High stated risk, but low GBP engagement
expressed_risk_but_low_exposure = gbp_behavior_df[
    (gbp_behavior_df['risk_tolerance'] >= risk_high) &
    (gbp_behavior_df['total_gbp_assets'] < asset_median)
]

# Case 2: Low stated risk, but high GBP exposure
low_risk_but_high_exposure = gbp_behavior_df[
    (gbp_behavior_df['risk_tolerance'] <= risk_low) &
    (gbp_behavior_df['total_gbp_assets'] > asset_top_25)
]

# Displaying results
print("⚠️ Expressed Risk Appetite, Low GBP Exposure")
display(expressed_risk_but_low_exposure)

print("\n⚠️ Expressed Caution, High GBP Exposure")
display(low_risk_but_high_exposure)

"""*Question 4: What patterns of diversification or currency preference emerge?*


"""

# Counting how many unique currencies each person holds
currency_diversity = assets_df.groupby('_id')['asset_currency'].nunique().reset_index()
currency_diversity.rename(columns={'asset_currency': 'num_currencies_held'}, inplace=True)

# Merging with personality dataframe
currency_risk_df = currency_diversity.merge(personality_df, on='_id', how='left')

# Distribution plot
plt.figure(figsize=(8, 4))
sns.countplot(x='num_currencies_held', data=currency_risk_df, palette='muted')
plt.title("Number of Currencies Held Per Individual")
plt.xlabel("Currencies Held")
plt.ylabel("Number of Individuals")
plt.grid(True)
plt.show()

# Comparing risk tolerance
multi_vs_single = currency_risk_df.copy()
multi_vs_single['currency_group'] = multi_vs_single['num_currencies_held'].apply(lambda x: 'Multi-Currency' if x > 1 else 'GBP-Only')

plt.figure(figsize=(8, 4))
sns.boxplot(x='currency_group', y='risk_tolerance', data=multi_vs_single, palette='pastel')
plt.title("Risk Tolerance: Multi-Currency vs. GBP-Only Holders")
plt.xlabel("")
plt.ylabel("Risk Tolerance")
plt.grid(True)
plt.show()

# Counting asset types (from 'asset_allocation' column)
allocation_counts = assets_df['asset_allocation'].value_counts()

# Plotting allocation type
plt.figure(figsize=(10, 4))
sns.barplot(x=allocation_counts.index, y=allocation_counts.values, palette='Set2')
plt.title("Distribution of Asset Allocation Types")
plt.xlabel("Asset Allocation Type")
plt.ylabel("Number of Assets")
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

"""*Question 5: What drives portfolio complexity?*

Risk Tolerance vs Currency Count
"""

# Already computed in Step 4 as currency_risk_df
corr_1 = currency_risk_df[['risk_tolerance', 'num_currencies_held']].corr().iloc[0, 1]
print(f"Correlation between risk tolerance and number of currencies held: {round(corr_1, 3)}")

"""Risk Tolerance vs. Crypto Allocation Share"""

# Counting total and crypto assets per user
total_assets_per_person = assets_df.groupby('_id')['asset_value'].count().reset_index(name='total_assets')
crypto_assets_per_person = assets_df[assets_df['asset_allocation'] == 'Crypto'] \
    .groupby('_id')['asset_value'].count().reset_index(name='crypto_assets')

# Merging and calculating share
allocation_df = total_assets_per_person.merge(crypto_assets_per_person, on='_id', how='left').fillna(0)
allocation_df['crypto_share'] = allocation_df['crypto_assets'] / allocation_df['total_assets']

# Merging with personality data
crypto_risk_df = allocation_df.merge(personality_df, on='_id', how='left')

# Correlation
corr_2 = crypto_risk_df[['risk_tolerance', 'crypto_share']].corr().iloc[0, 1]
print(f"Correlation between risk tolerance and crypto asset share: {round(corr_2, 3)}")

"""*BEHAVIOURAL OUTLIER SPOTLIGHT*"""

# Step 1: Total GBP holdings per person
gbp_assets_person = gbp_assets.groupby('_id')['asset_value'].sum().reset_index()
gbp_assets_person.rename(columns={'asset_value': 'total_gbp_assets'}, inplace=True)

# Step 2: Merging GBP holdings with risk tolerance
gbp_behavior_df = gbp_assets_person.merge(personality_df, on='_id', how='left')

# Step 3: Total and Crypto Assets Per Person
total_assets = assets_df.groupby('_id')['asset_value'].count().reset_index(name='total_assets')
crypto_assets = assets_df[assets_df['asset_allocation'] == 'Crypto'] \
    .groupby('_id')['asset_value'].count().reset_index(name='crypto_assets')

# Merging and calculating crypto share
crypto_share_df = total_assets.merge(crypto_assets, on='_id', how='left').fillna(0)
crypto_share_df['crypto_share'] = crypto_share_df['crypto_assets'] / crypto_share_df['total_assets']

# Merging with personality
crypto_risk_df = crypto_share_df.merge(personality_df, on='_id', how='left')

# Adding risk category label for average zone
crypto_risk_df['risk_category'] = crypto_risk_df['risk_tolerance'].apply(
    lambda x: 'Average Risk' if 0.45 <= x <= 0.55 else 'Other'
)

# 1. High Risk Tolerance, Low GBP Exposure
high_risk_low_gbp = gbp_behavior_df[
    (gbp_behavior_df['risk_tolerance'] >= 0.7) &
    (gbp_behavior_df['total_gbp_assets'] < gbp_behavior_df['total_gbp_assets'].median())
]

print("🔹 High Risk, Low GBP Exposure")
display(high_risk_low_gbp[['_id', 'risk_tolerance', 'total_gbp_assets']])

# 2. Low Risk Tolerance, High GBP Exposure
low_risk_high_gbp = gbp_behavior_df[
    (gbp_behavior_df['risk_tolerance'] <= 0.4) &
    (gbp_behavior_df['total_gbp_assets'] > gbp_behavior_df['total_gbp_assets'].quantile(0.75))
]

print("🔹 Low Risk, High GBP Exposure")
display(low_risk_high_gbp[['_id', 'risk_tolerance', 'total_gbp_assets']])

# 3. Crypto-Heavy, Behaviorally Average
crypto_heavy_avg_risk = crypto_risk_df[
    (crypto_risk_df['crypto_share'] >= 0.75) &
    (crypto_risk_df['risk_category'] == 'Average Risk')
]

print("🔹 Crypto-Heavy with Average Risk Tolerance")
display(crypto_heavy_avg_risk[[
    '_id', 'risk_tolerance', 'crypto_share', 'total_assets', 'crypto_assets'
]])